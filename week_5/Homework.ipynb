{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54269ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f965eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 10:49:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcce855",
   "metadata": {},
   "source": [
    "### Downloading FHVHV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d744d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-06 10:17:10--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T101710Z&X-Amz-Expires=300&X-Amz-Signature=3beec242d578169485141e0f4fb33d730d5e73ac163b47e4931eebd8203dad76&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-06 10:17:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T101710Z&X-Amz-Expires=300&X-Amz-Signature=3beec242d578169485141e0f4fb33d730d5e73ac163b47e4931eebd8203dad76&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 175799316 (168M) [application/octet-stream]\n",
      "Saving to: ‘fhvhv_tripdata_2021-06.csv.gz’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 167.66M  71.3MB/s    in 2.4s    \n",
      "\n",
      "2023-03-06 10:17:13 (71.3 MB/s) - ‘fhvhv_tripdata_2021-06.csv.gz’ saved [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77965653",
   "metadata": {},
   "source": [
    "### Downloading the Zone Lookup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d6c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-06 10:23:35--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T102335Z&X-Amz-Expires=300&X-Amz-Signature=2a17b2c5a01454ff17e970ddd630f29e68defc8909205ac2c6026443d111f7aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-06 10:23:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T102335Z&X-Amz-Expires=300&X-Amz-Signature=2a17b2c5a01454ff17e970ddd630f29e68defc8909205ac2c6026443d111f7aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-03-06 10:23:36 (18.7 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d337e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02764|2021-06-01 00:02:41|2021-06-01 00:07:46|         174|          18|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:16:16|2021-06-01 00:21:14|          32|         254|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:27:01|2021-06-01 00:42:11|         240|         127|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:46:08|2021-06-01 00:53:45|         127|         235|      N|                B02764|\n",
      "|              B02510|2021-06-01 00:45:42|2021-06-01 01:03:33|         144|         146|      N|                  null|\n",
      "|              B02510|2021-06-01 00:18:15|2021-06-01 00:25:47|          49|          17|      N|                  null|\n",
      "|              B02510|2021-06-01 00:33:06|2021-06-01 00:42:46|          49|         225|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:27|2021-06-01 00:56:50|         225|         177|      N|                  null|\n",
      "|              B02764|2021-06-01 00:48:06|2021-06-01 01:04:10|         209|          45|      N|                B02764|\n",
      "|              B02875|2021-06-01 00:18:54|2021-06-01 00:26:14|          80|         256|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:31:02|2021-06-01 00:36:39|         217|          17|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:41:53|2021-06-01 01:07:32|          17|         265|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:29:52|2021-06-01 00:54:41|         210|          76|      N|                B02875|\n",
      "|              B02510|2021-06-01 00:15:57|2021-06-01 00:39:36|         226|         213|      N|                  null|\n",
      "|              B02510|2021-06-01 00:11:59|2021-06-01 00:23:32|         191|           9|      N|                  null|\n",
      "|              B02510|2021-06-01 00:30:35|2021-06-01 00:45:35|          16|         250|      N|                  null|\n",
      "|              B02510|2021-06-01 00:49:01|2021-06-01 01:03:50|         182|         259|      N|                  null|\n",
      "|              B02510|2021-06-01 00:07:36|2021-06-01 00:21:13|         188|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:25:48|2021-06-01 00:40:43|          39|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:11|2021-06-01 00:53:39|          72|          35|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')\n",
    "\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5115cfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dac7482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_p).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae6ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990c8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a69f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02764|2021-06-01 00:02:41|2021-06-01 00:07:46|         174|          18|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:16:16|2021-06-01 00:21:14|          32|         254|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:27:01|2021-06-01 00:42:11|         240|         127|      N|                B02764|\n",
      "|              B02764|2021-06-01 00:46:08|2021-06-01 00:53:45|         127|         235|      N|                B02764|\n",
      "|              B02510|2021-06-01 00:45:42|2021-06-01 01:03:33|         144|         146|      N|                  null|\n",
      "|              B02510|2021-06-01 00:18:15|2021-06-01 00:25:47|          49|          17|      N|                  null|\n",
      "|              B02510|2021-06-01 00:33:06|2021-06-01 00:42:46|          49|         225|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:27|2021-06-01 00:56:50|         225|         177|      N|                  null|\n",
      "|              B02764|2021-06-01 00:48:06|2021-06-01 01:04:10|         209|          45|      N|                B02764|\n",
      "|              B02875|2021-06-01 00:18:54|2021-06-01 00:26:14|          80|         256|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:31:02|2021-06-01 00:36:39|         217|          17|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:41:53|2021-06-01 01:07:32|          17|         265|      N|                B02875|\n",
      "|              B02875|2021-06-01 00:29:52|2021-06-01 00:54:41|         210|          76|      N|                B02875|\n",
      "|              B02510|2021-06-01 00:15:57|2021-06-01 00:39:36|         226|         213|      N|                  null|\n",
      "|              B02510|2021-06-01 00:11:59|2021-06-01 00:23:32|         191|           9|      N|                  null|\n",
      "|              B02510|2021-06-01 00:30:35|2021-06-01 00:45:35|          16|         250|      N|                  null|\n",
      "|              B02510|2021-06-01 00:49:01|2021-06-01 01:03:50|         182|         259|      N|                  null|\n",
      "|              B02510|2021-06-01 00:07:36|2021-06-01 00:21:13|         188|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:25:48|2021-06-01 00:40:43|          39|          72|      N|                  null|\n",
      "|              B02510|2021-06-01 00:46:11|2021-06-01 00:53:39|          72|          35|      N|                  null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')\n",
    "\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fba9b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a45f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7507a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('homework/2021/06/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89bfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.parquet('homework/2021/06/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132d3bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14961892"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9342c46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "610521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, unix_timestamp, from_unixtime\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e2c1324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+----------------+-----------------+----------------+-------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|pickup_date|pickup_timestamp|dropoff_timestamp|duration_seconds|trip_duration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+----------------+-----------------+----------------+-------------+\n",
      "|              B02889|2021-06-04 20:51:44|2021-06-04 21:10:12|         239|         158|      N|                B02889| 2021-06-04|      1622839904|       1622841012|            1108|     00:18:28|\n",
      "|              B02800|2021-06-04 15:50:15|2021-06-04 16:19:29|          75|         116|      N|                  null| 2021-06-04|      1622821815|       1622823569|            1754|     00:29:14|\n",
      "|              B02510|2021-06-02 21:03:38|2021-06-02 21:10:12|         167|         168|      N|                  null| 2021-06-02|      1622667818|       1622668212|             394|     00:06:34|\n",
      "|              B02867|2021-06-02 12:51:57|2021-06-02 13:05:09|         151|         142|      N|                B02867| 2021-06-02|      1622638317|       1622639109|             792|     00:13:12|\n",
      "|              B02869|2021-06-21 09:51:45|2021-06-21 10:09:17|         106|          65|      N|                B02869| 2021-06-21|      1624269105|       1624270157|            1052|     00:17:32|\n",
      "|              B02764|2021-06-02 13:27:03|2021-06-02 13:38:20|         113|         148|      N|                B02764| 2021-06-02|      1622640423|       1622641100|             677|     00:11:17|\n",
      "|              B02764|2021-06-10 14:48:23|2021-06-10 16:06:10|         250|         239|      N|                B02764| 2021-06-10|      1623336503|       1623341170|            4667|     01:17:47|\n",
      "|              B02510|2021-06-09 22:38:49|2021-06-09 23:11:58|         132|          33|      N|                  null| 2021-06-09|      1623278329|       1623280318|            1989|     00:33:09|\n",
      "|              B02510|2021-06-26 06:50:43|2021-06-26 07:00:20|         238|         244|      N|                  null| 2021-06-26|      1624690243|       1624690820|             577|     00:09:37|\n",
      "|              B02872|2021-06-07 08:04:00|2021-06-07 08:40:25|         198|         234|      N|                B02872| 2021-06-07|      1623053040|       1623055225|            2185|     00:36:25|\n",
      "|              B02765|2021-06-24 20:19:42|2021-06-24 20:38:22|         147|          42|      N|                B02765| 2021-06-24|      1624565982|       1624567102|            1120|     00:18:40|\n",
      "|              B02884|2021-06-05 17:38:24|2021-06-05 18:05:30|         142|         232|      N|                B02884| 2021-06-05|      1622914704|       1622916330|            1626|     00:27:06|\n",
      "|              B02765|2021-06-13 15:44:27|2021-06-13 16:04:38|          26|         165|      N|                B02765| 2021-06-13|      1623599067|       1623600278|            1211|     00:20:11|\n",
      "|              B02510|2021-06-26 18:37:10|2021-06-26 18:56:01|         237|         145|      N|                  null| 2021-06-26|      1624732630|       1624733761|            1131|     00:18:51|\n",
      "|              B02764|2021-06-23 14:44:10|2021-06-23 14:58:06|          45|          33|      N|                B02764| 2021-06-23|      1624459450|       1624460286|             836|     00:13:56|\n",
      "|              B02510|2021-06-20 02:11:32|2021-06-20 02:22:00|          49|          37|      N|                  null| 2021-06-20|      1624155092|       1624155720|             628|     00:10:28|\n",
      "|              B02764|2021-06-29 19:02:50|2021-06-29 19:05:25|         140|         140|      N|                B02764| 2021-06-29|      1624993370|       1624993525|             155|     00:02:35|\n",
      "|              B02875|2021-06-02 15:27:05|2021-06-02 15:37:27|          32|         185|      N|                B02875| 2021-06-02|      1622647625|       1622648247|             622|     00:10:22|\n",
      "|              B02882|2021-06-18 12:48:43|2021-06-18 12:58:22|          95|         134|      N|                B02882| 2021-06-18|      1624020523|       1624021102|             579|     00:09:39|\n",
      "|              B02510|2021-06-23 08:59:54|2021-06-23 09:44:49|         171|         140|      N|                  null| 2021-06-23|      1624438794|       1624441489|            2695|     00:44:55|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+----------------+-----------------+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df3.withColumn('pickup_date', to_date(df3['pickup_datetime']).cast(DateType()))\n",
    "df4 = df4.withColumn(\"pickup_timestamp\", unix_timestamp(df3[\"pickup_datetime\"]))\n",
    "df4 = df4.withColumn(\"dropoff_timestamp\", unix_timestamp(df3[\"dropoff_datetime\"]))\n",
    "df4 = df4.withColumn(\"duration_seconds\", df4[\"dropoff_timestamp\"] - df4[\"pickup_timestamp\"])\n",
    "df4 = df4.withColumn(\"trip_duration\", from_unixtime(df4[\"duration_seconds\"], format=\"HH:mm:ss\"))\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68f7c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+-------------------+-----------------+-------------+\n",
      "|    pickup_datetime|pickup_timestamp|   dropoff_datetime|dropoff_timestamp|trip_duration|\n",
      "+-------------------+----------------+-------------------+-----------------+-------------+\n",
      "|2021-06-04 20:51:44|      1622839904|2021-06-04 21:10:12|       1622841012|     00:18:28|\n",
      "|2021-06-04 15:50:15|      1622821815|2021-06-04 16:19:29|       1622823569|     00:29:14|\n",
      "|2021-06-02 21:03:38|      1622667818|2021-06-02 21:10:12|       1622668212|     00:06:34|\n",
      "|2021-06-02 12:51:57|      1622638317|2021-06-02 13:05:09|       1622639109|     00:13:12|\n",
      "|2021-06-21 09:51:45|      1624269105|2021-06-21 10:09:17|       1624270157|     00:17:32|\n",
      "|2021-06-02 13:27:03|      1622640423|2021-06-02 13:38:20|       1622641100|     00:11:17|\n",
      "|2021-06-10 14:48:23|      1623336503|2021-06-10 16:06:10|       1623341170|     01:17:47|\n",
      "|2021-06-09 22:38:49|      1623278329|2021-06-09 23:11:58|       1623280318|     00:33:09|\n",
      "|2021-06-26 06:50:43|      1624690243|2021-06-26 07:00:20|       1624690820|     00:09:37|\n",
      "|2021-06-07 08:04:00|      1623053040|2021-06-07 08:40:25|       1623055225|     00:36:25|\n",
      "|2021-06-24 20:19:42|      1624565982|2021-06-24 20:38:22|       1624567102|     00:18:40|\n",
      "|2021-06-05 17:38:24|      1622914704|2021-06-05 18:05:30|       1622916330|     00:27:06|\n",
      "|2021-06-13 15:44:27|      1623599067|2021-06-13 16:04:38|       1623600278|     00:20:11|\n",
      "|2021-06-26 18:37:10|      1624732630|2021-06-26 18:56:01|       1624733761|     00:18:51|\n",
      "|2021-06-23 14:44:10|      1624459450|2021-06-23 14:58:06|       1624460286|     00:13:56|\n",
      "|2021-06-20 02:11:32|      1624155092|2021-06-20 02:22:00|       1624155720|     00:10:28|\n",
      "|2021-06-29 19:02:50|      1624993370|2021-06-29 19:05:25|       1624993525|     00:02:35|\n",
      "|2021-06-02 15:27:05|      1622647625|2021-06-02 15:37:27|       1622648247|     00:10:22|\n",
      "|2021-06-18 12:48:43|      1624020523|2021-06-18 12:58:22|       1624021102|     00:09:39|\n",
      "|2021-06-23 08:59:54|      1624438794|2021-06-23 09:44:49|       1624441489|     00:44:55|\n",
      "+-------------------+----------------+-------------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select('pickup_datetime','pickup_timestamp', 'dropoff_datetime','dropoff_timestamp', 'trip_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22a21222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.select('pickup_date').filter(df4.pickup_date == '2021-06-15').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eb16f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df4.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c61259df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|duration_seconds|trip_duration|\n",
      "+----------------+-------------+\n",
      "|          240764|     18:52:44|\n",
      "|           91979|     01:32:59|\n",
      "|           71931|     19:58:51|\n",
      "|           65510|     18:11:50|\n",
      "|           59281|     16:28:01|\n",
      "|           51368|     14:16:08|\n",
      "|           50075|     13:54:35|\n",
      "|           42012|     11:40:12|\n",
      "|           40917|     11:21:57|\n",
      "|           39544|     10:59:04|\n",
      "|           36963|     10:16:03|\n",
      "|           35879|     09:57:59|\n",
      "|           35879|     09:57:59|\n",
      "|           34696|     09:38:16|\n",
      "|           34648|     09:37:28|\n",
      "|           34129|     09:28:49|\n",
      "|           34098|     09:28:18|\n",
      "|           33848|     09:24:08|\n",
      "|           33817|     09:23:37|\n",
      "|           33757|     09:22:37|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT duration_seconds, trip_duration\n",
    "FROM trips_data\n",
    "ORDER BY duration_seconds desc\n",
    "\"\"\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b6023b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f744a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9584eec1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) pickup_datetime#84 missing from hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364 in operator !Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#440]. Attribute(s) with the same name appear in the operation: pickup_datetime. Please check if the right attribute(s) are used.;\n!Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#440]\n+- Relation [hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_171714/2979810901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickup_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_datetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropoff_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_datetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickup_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropoff_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PULocationID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DOLocationID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) pickup_datetime#84 missing from hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364 in operator !Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#440]. Attribute(s) with the same name appear in the operation: pickup_datetime. Please check if the right attribute(s) are used.;\n!Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#440]\n+- Relation [hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364] parquet\n"
     ]
    }
   ],
   "source": [
    "df3 \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e891d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) pickup_datetime#84 missing from hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364 in operator !Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#439]. Attribute(s) with the same name appear in the operation: pickup_datetime. Please check if the right attribute(s) are used.;\n!Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#439]\n+- Relation [hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_171714/3965588209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickup_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_datetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropoff_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_datetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    .select('base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) pickup_datetime#84 missing from hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364 in operator !Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#439]. Attribute(s) with the same name appear in the operation: pickup_datetime. Please check if the right attribute(s) are used.;\n!Project [hvfhs_license_num#358, dispatching_base_num#359, pickup_datetime#360, dropoff_datetime#361, PULocationID#362, DOLocationID#363, SR_Flag#364, to_date(pickup_datetime#84, None, Some(Etc/UTC)) AS pickup_date#439]\n+- Relation [hvfhs_license_num#358,dispatching_base_num#359,pickup_datetime#360,dropoff_datetime#361,PULocationID#362,DOLocationID#363,SR_Flag#364] parquet\n"
     ]
    }
   ],
   "source": [
    "df3.withColumn('pickup_date', F.to_date(df.pickup_datetime)).withColumn('dropoff_date', F.to_date(df.dropoff_datetime)).show()\n",
    "#    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "#    .select('base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845322d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
